FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 1 of 17, EVP and CFO
, Analyst
Unidentiﬁed Participant, Analyst, Unknown
Joe Mayer
Colette KressMorgan Stanley Technology, Media & Telecom
Conference
Company Participants
Colette Kress
Joe Mayer
Other Participants
Presentation
{BIO 1470363 <GO>}
I'm Joe Mayer, Morgan Stanley Research. Very happy to have today Colette Kress
from NVIDIA. I wish, Colette, that the meeting we had here last year, I'd just listened
to everything you told me and just believed it.
(Laughter)
(inaudible) a lot better. You guys had a great year, obviously. So thank you so much
for being here. I know there's a lot of anticipation. Maybe we'll just get right into it.
Maybe start with just the gaming business, because that seems like the focus people
have right now -- 59% of your revenues. You had a great year, you grew 44%, 59%
sequentially in the Third Quarter, which is -- I've never seen a business of that size
kind of have that kind of unexpected growth.
Can you talk about what drove that. And what makes you guys bullish about gaming
oﬀ that base going forward?
{BIO 18297352 <GO>}
Sure. So gaming -- it is the basis of our company and has been for more than 15, 20
years. We built the Company as one of the key applications for the GPU was gaming.
And we have really changed our approach to gaming over the last several years.
And last year is one of those key years for us as well.
So last year was about continuing to evolve the overall gaming industry. The gaming
industry used to start where it was a one-on-one play. Right? Yourself with the overall
computer. And it's really moved to a social platform. It's moved to a social platformFINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 2 of 17to where you are playing with all of your friends. It's not just about one gamer at a
time. They're usually two-by-two or more, because they're all playing with their
overall friends. So our approach has been to enable a gaming platform for every
type of gamer that will be there.
And we have a lot of diﬀerent cards. And last year took place in terms of enabling
Pascal to come to market. Pascal is an amazing architecture, an architecture that
we're using across the Company; but, very importantly, in terms of our launch, in
terms of for gaming, that we brought to market probably the most cards that we
have ever done over a shorter period of time. Very successful overall launch; very,
very strong acceptance of those cards and their performance.
Its performance improvements that are detainable [ph] from the last generation was
substantial. But even those that have been on our platform for many years, it was
essentially a no-brainer type of thought in terms of the upgrade potential that we
could do.
We approach the Pascal architecture as an opportunity for us to enable in the future.
If you ever want to play VR, you have that ability in terms of the Pascal.
So through a combination of what we see in terms of an expanding market of
gamers -- gamers that are coming onboard for the social experience, gamers that
are staying on longer, gamers that are coming onboard where broadband access
has never been in the past -- now have those ability to enjoy what they see in terms
of sister countries nearby them.
Then, also, what we have is probably the best architecture, the best overall platform,
in terms of in the market. And we've been able to continue to both increase those
units and increase those overall ASPs for the gamers.
But there's a lot of discussion that says -- well, what now? A very, very strong second
half. We're talking about gaming overall results growing more than 60% year over
year in those two quarters. The underlying fundamentals of the gaming industry are
still there. They are still taking place while things change [ph].
If you were with us last night, also here in San Francisco, at GDC just down the street,
we actually announced yet another Pascal card. We announced a 1080 Ti, which is
again 35% in performance improvement over our existing 1080 that is in market. We
also made room in terms of our overall price points for that 1080 to come in at a
$699 price point.
So again, we are enabling all the diﬀerent types of enthusiastic gamers that are out
there to partake in terms of the gaming, with all the diﬀerent types of price points
and great cards that we have.
So we still believe those healthy parts of the market are there for us to capture.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 3 of 17Joe Mayer
Colette Kress
Joe Mayer{BIO 1470363 <GO>}
Then, I guess, how do you parse the product cycle aspect? Because Pascal was
obviously a huge cycle. And you talked about the reasons why people are adopting
faster. You've rolled out a lot of families quicker, although it's actually pretty exciting,
you have new families to talk about. But is that an adoption cycle that you then sort
of consolidate your revenue gains at that point? Or do you see that number
continuing to grow from that level?
And I think, I guess, it's also encouraging to me that we've seen growth in PC
gaming software stronger than we've seen in a long time as well over the last couple
quarters. And how much of it is an adoption cycle versus the growth aspects in the
population of (inaudible)?
{BIO 18297352 <GO>}
Yes, I think that's a good question. Because with the rollout of all of the diﬀerent
platforms that we had, is all of that upgrade complete? And the answer is absolutely
not. The overall cycle for how often they will actually refresh their overall gaming
platform may be somewhere between three-and-a-half, four years. It's still too early
for us to tell. It takes three-and-a-half, four years to determine if that cycle is still the
same.
When we compare and look at how well we're doing against our last architecture in
terms of Maxwell, it's still really early, because we're only about two quarters in of
selling through our overall Pascal, over a process that should take about three-and-a-
half to four years. But so far, we're moving faster, a little bit faster, than when we did
at Pascal. So we feel great about that.
But I think you can see that the establishment of more gamers out there is also,
overall, driving our ability to sell in in terms of the additional units. And it's not just
necessarily just a refresh.
It will take us a little bit more time to see that through. But we'll probably see that
continue and that refreshing to occur all the way through the current year that we're
into.
{BIO 1470363 <GO>}
Okay, that's helpful.
And I guess one of the helpful distinctions you guys have made in the last few years
is this OEM versus gaming. And OEM has been declining. Gaming has actually been
growing at a good clip for quite some time. It's just showing up more now. And it's
getting to be a bigger part of the numbers. Can you talk a little bit about how you're
parsing that. And why you've seen that shift?FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 4 of 17Colette Kress
Joe Mayer
Colette Kress
Joe Mayer{BIO 18297352 <GO>}
Sure.
So we took that opportunity a couple years ago to really concentrate on our game
platforms. We sell GPUs for general-purpose PCs, probably several of the ones that
are out here in the audience today. That said, sure, there's a little bit of graphic
capability that we want for certain applications that you will be -- but there is a
diﬀerent level to play several of the high-end games.
So we really market and build certain platforms that are exclusively for that gaming
market. And we classify those as gaming. Most of the time, it's in the range of
probably about a $100 price point or more for those markets, where we feel people,
when they are spending that much money, we can actually see them through our
GeForce experience -- sign on, download the drivers for games. So we have an
ability to actually look to say yes, the intended use of those overall gaming platforms
are actually being used for gaming.
So that's essentially how we have split through our overall OEM business. It's a very
small part of our business now. It represents probably less than 5% of our business.
It's not necessarily growish at this time, because we're still not at the point that
overall PC growth is there; or even that a discrete GPU attached is the strong
reasons, in terms of something that you would buy in terms of the PC.
We will still be strategically aligned to the OEMs and those PC platforms, in terms of
supporting it. But it's diﬀerent price point at the diﬀerent ASPs. There can be
signiﬁcant amounts of just volumes, just because of the mass amounts of PCs out
there. But again, it's a very small part of our business.
{BIO 1470363 <GO>}
Okay. That's helpful.
Then, the other divisive point in terms of your gaming business. And where I think
investors are all over the map, is how much of the growth is price versus units. And I
know you don't go into those distinctions. But maybe qualitatively, some people are
of the view that it's all price. It seems to us that it's more units than price and that,
actually, like-for-like pricing hasn't changed that much, Maxwell to Pascal. And that
you're probably getting some people trading up to the higher-end SKUs. So can you
talk a little bit about that?
{BIO 18297352 <GO>}
Yes. The good old discussion about ASPs versus unit growth --
{BIO 1470363 <GO>}FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 5 of 17Colette Kress
Joe MayerYou can just give it to the top line.
{BIO 18297352 <GO>}
We could, we could go through there.
So we did take an opportunity, about a year, to look at what we have seen historically
over the last couple years in terms of our ASPs and our unit growth in gaming. Keep
in mind, if you looked from day to day, month to month, given what we launch,
sometimes we launch what we know is going to be more of a volume play. Then we
launch some that we know is going to be more of a high-end card that's going to be
to a certain part of the market, which will essentially drive our ASPs.
So looking at it over a very short period of time, you may have some interesting
things that pop out of that. So what we have done is we've looked over a long
period of time. Based on what we see as those factors, you are seeing both. You are
seeing a growth in terms of units, we are seeing a growth in ASPs.
Over the last ﬁve years, the overall gaming business, about a half a year ago, was
growing about 30%, 30% growth on the top line. Faster, yes, than the overall gaming
market below. And what we talked about was the unit growth is probably about 9%.
And the ASP growth was about 11%. Those are a multiplying factor to get to the
overall 30%.
As we ﬁnish ﬁscal year 2017 and our growth in terms of being around a little bit
higher than 30%, probably in the mid-30s or higher over that same type of CAGR
period, those same factors are occurring. Nothing has materially changed, other
than a very, very strong part of [ph] 2017 that helped. So I think we're still seeing the
same aspects of growth in ASPs as well as growth in terms of units.
You responded of [ph] did we increase our prices with Pascal? And the answer is
really not. When you think about the overall price for performance, it is about the
same that we've said. Or, another way of saying is, in many times, you're actually
getting more performance at a better price that we're doing. And that is our goal.
Our goal is not to just overall increase price, it turns out.
But what you are seeing is people continuing to choose a higher-end card to play
their games. They truly see the beneﬁts of sometimes playing the exact same game
with a better GPU is a better experience. It's like playing a diﬀerent game. And so we
do get those beneﬁts from them just upgrading on their next time of buying a GPU
at a higher card. And that is also, therefore, in our overall ASP grip.
{BIO 1470363 <GO>}
Okay. That's helpful.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 6 of 17Colette Kress
Joe Mayer
Colette KressThen, the other element that people ask me about is other ways of boosting the
dollar per customer, whether it's the Founders Edition card or selling DRAM or those
kinds of things. My sense is those things are pretty small. But can you just address
that?
{BIO 18297352 <GO>}
Yes. They are pretty small. We get the question of the Founder Edition -- what was
our goal? What was the overall excitement about why, in terms of the Founders
Edition? It's a small percentage. But if you think about how the launch process works,
from last night to when a gamer will actually be able to receive a 1080 Ti, which will
be next week. And that's because we have put in a Founder Edition, which allows us
to build these boards and be ready as close to launch as possible. That takes that
excitement that they have at a launch. And they can feel that excitement in about a
week, to when they actually received it. It's still a very small percentage.
The price point of the Founder Edition is also just slightly higher. But keep in mind,
there's also diﬀerent components with that. We felt if we were actually selling it from
the Company ourselves, they would expect the high-end components, the rich
components that we could put in there. Given that we do not have a volume play in
terms of those components, we just have a slightly higher price to keep that.
But really, our overall purpose of that is to just keep the excitement from the launch
that they can receive the overall card quite quickly. So that's one piece of it. But
you're right, it's not a material part of it.
{BIO 1470363 <GO>}
Okay. Great.
So overall, it sounds like you're pretty constructive on the growth of this gaming
segment. There's, I guess, a view that there's been some discontinuity more recently.
And yet, seems like your guidance was for generally seasonal kinds of results. Is that
the way you're looking at the current quarter?
{BIO 18297352 <GO>}
Yes. The gaming market does have its seasonality with it. Probably one of the -- one
seasonality that we can see versus all of the markets that we are in. And that
seasonality is stronger in the second half of the year than the ﬁrst half of the year.
Sometimes, that growth in terms of the second half of the year is largely inﬂuenced
by the holiday seasons. And I mean seasons, because it's worldwide holidays. It's not
just those here in the Western world that inﬂuences that. And we've seen that.
And so you're going to likely see the ﬁrst half to be diﬀerent than what we've seen in
the second half of the year. Given the strength that we had in ﬁscal year 2017, that
seasonality is still there. And given what we can see in terms of Q1, that seasonality
will probably continue.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 7 of 17Joe Mayer
Colette Kress
Joe Mayer
Colette Kress
Joe Mayer{BIO 1470363 <GO>}
Okay. Great.
Then, one last question on the gaming topic -- the AMD competition -- this time last
year, I feel like people were worried about AMD's Polaris, which turned out to be
pretty much entry level. Platform did very well for them but is at an entry level. Now,
we're talking about Vega challenging you more in the high end. At least, that's their
aspiration. Can you talk about what you're hearing from customers. And just how we
should think about market share?
{BIO 18297352 <GO>}
Sure.
We've been competing with AMD since the beginning of time. And as the other
discrete market player there. We have a diﬀerent way we go to market, though. We
really have a diﬀerent way that we actually approach that gamer. We look at it as,
how do we surround the ecosystem around the gamer with GeForce Experience,
additional features that you can enable for certain games, working with the overall
software developers? We don't approach it as an OEM sale. We have a delightful
partner channel that we work with to reach all of those diﬀerent gamers.
So although AMD will continue down that same path on how they've gone to market,
which just [ph] says let's talk about the performance, we've still also continued to
out-beat performance. And I think that's what our gamers demand after us. They
demand the best-of-breed. And that brand loyalty, I think, is there.
So we know how to compete against them. We have been competing them. We
have heard that they might come out with Vega. They've been talking about it for a
while. But I think we're well prepared. I think our 1080 Ti, being signiﬁcantly better
than even our 1080, which I had seen some comparisons of comparing Vega to 1080
-- I'm not sure we're following the same type of game, if they always know that we'll
always having something better to come out with.
{BIO 1470363 <GO>}
Okay.
{BIO 18297352 <GO>}
But I think the 1080 Ti, even already, is a great piece for us to launch with.
{BIO 1470363 <GO>}
Okay. That's helpful.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 8 of 17Colette Kress
Joe Mayer
Colette KressAnd before I leave the graphics business, I did want to touch on the enterprise, the
Pro Visualization business. You guys have talked about that as a GDP growth type of
business. And yet it grew double digits last year. Can you talk about what drove that?
And is there any possibility of optimization?
{BIO 18297352 <GO>}
Sure.
So Pro Visualization -- the same importance of using graphics in the enterprise is very
key to many diﬀerent types of businesses. And the importance of the mobility for
them is very key for collaboration and for them to overall do their work.
So what we have seen is the mobile workforce, in terms of wanting that high-
performance GPU in a thin-and light. And moving to form factors that allow them to
take their work and do their work everywhere. So we have continued to move to
higher-end GPUs in about as thin of a workstation that we can overall get. And that is
coming through.
Secondly, you see the ability to render on the spot, the ability for them to render
quickly, to smooth out that process and the timing with the high-end GPUs and
leveraging the GPU to use the rendering. So they are taking advantage, again, of
some of our highest-end GPUs. And that is becoming very successful in terms of the
growth rate.
We're very, very pleased with the growth rate of Proviz -- a very mature, very well-
established leadership position that we have. But we were able to grow at 11% this
last year.
We'll continue to focus on the mobility. We'll continue to focus on enabling better
and better rendering as we move forward. So those are going to be our options.
{BIO 1470363 <GO>}
Okay. Great.
So shifting gears, I mean, the other, obviously exciting part of the story -- less
divisive, I think -- it's one we're all excited about it -- is your datacenter-oriented
business. You grew 144% last year. And it's up to 14% of sales amount [ph]. So it's
starting to really move the needle. Can you give us an overview of that business. And
maybe talk about how that splits out between the high-performance compute, the
traditional part, the deep learning in businesses like GRID?
{BIO 18297352 <GO>}
Yes.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 9 of 17So the success in our datacenter business, we couldn't be more pleased. I know a lot
of other folks in the datacenter business really talk about their growth rates. But
when you leave Q4 with tripling, it's doing pretty good on that part. But it does
enable many diﬀerent businesses underneath it. So I think it would be good for us to
understand all of those diﬀerent pieces.
Yes, our high-performance computing business is in there. Our high-performance
computing business has been with us for eight to 10 years. That is when we are
solving mathematical computations using accelerated computing, areas where, sure,
we can derive the overall formulas, we can move that to working in a parallel
function and breaking that apart. But we know the answer. And using accelerated
computing such as a GPU is very successful. That business is still growing quite
nicely and is the core part and the starting point of our datacenter business.
But over the last couple of years, we've seen the evolution and the beginnings of AI.
And primarily the use of deep learning training. That had started in one of our
second businesses, which is deep learning with our overall hyperscales, where they
are using deep learning training for applications and workloads that you and I use
every day. Search commands, voice search commands, image detection, natural
language processing, video encoding are some of those things that you see. So that
business is deﬁnitely thriving and has been a great opportunity for us.
But thirdly, we have also seen the evolution that says -- how do you get to the
enterprises? How do you move this AI and deep learning. And the computing
capability of accelerated computing, using your GPU, to the enterprises?
In the past, maybe 10 or 15 years ago, your IT departments would go oﬀ and build
that. What we're seeing is the build-out of cloud instances, cloud instances by our
cloud service providers that are enabling GPU instances. And so that is also a key
component of our datacenter business now, as many of those cloud service
providers that you have seen continue to launch GPU instances.
Now, those GPU instances can be used for many things -- one, deﬁnitely for AI and
deep learning training that the enterprises can get started, in terms of it's already set
up. And things that they wouldn't do on-premise now that they can do in the cloud.
Number two, you also have the ability to do virtualization in the cloud. You have the
ability to put workstations, applications or PCs in your cloud and have that available
in a virtualized scenario as well. Then, number three, just doing overall compute. If
you want to do high-performance computing in the cloud, you also have that overall
capability. So that's an area of our third business that was growing.
That then takes us to our overall GRID business. Our GRID business outside of just
the cloud is also enterprises installing it in their on-premise businesses as well, in
order to expand their overall workforce for collaboration and not be just tied to their
overall workstation; be able to show that across the world.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 10 of 17Joe Mayer
Colette KressThen, lastly, our DGX supercomputing AI -- we also have that as an ability for the
enterprises for quick-start. We're talking about a fully contained AI supercomputer
with eight GPUs, with an overall computing development platform, inclusive of all of
the diﬀerent frameworks that are out there for deep learning; and the abilities for
enterprises to just plug it in and get started with what you see right now is the big
excitement around AI.
So all of those ﬁve diﬀerent businesses are in there. AI [ph] is probably the fastest-
growing piece of that, deﬁnitely, in terms of our datacenter business.
{BIO 1470363 <GO>}
Thank you for that. The deep learning piece in particular, I think, is pretty exciting,
given the priority that the cloud companies are putting on deep learning, the things
that it's enabling in terms of particularly visual data -- entirely new functions.
But I guess it's a hard business to size. And I know you've sort of resisted the
temptation to put a cap on how big it can get. But how do you think about it? Are
there multiple years of runway here? And should we think of it in terms of attach
rates for traditional CPUs, or should we think of it as its own thing, supporting its own
workloads?
{BIO 18297352 <GO>}
Yes. It's a good question. I think the challenge is not what I would refer to as a
hesitation [ph]. I think it's more of a -- I think it's very diﬃcult in the ﬁrst couple years
to take a dot and extrapolate it to a line. That's a hard problem to do, to say, when
you're in the ﬁrst couple innings, what we're seeing in terms of an AI market.
I think we truly believe that what we see in datacenter, what we see AI, is a new
computing model that will be with us for decades as we move forward. And we are
still just in the early stages. So it's hard.
Your second part of that question, though, says, where do you start? Do you do it as
an attach rate to a CPU? Or is there another way that you could do in terms of a
bottoms-up from a workload? And the answer is both. But there is some ﬂaws in
terms of both ways.
If you come from a tops-down approach and, say, a percentage of that will be -- if
you're oﬀ a single digit, it can be half a billion dollars here and there. So it's not
necessarily overly accurate at the stage that we're seeing. Again, as we get a little bit
farther, I think that would be a little bit easier.
But I think it's important to look at the types of workloads that are very interested.
And/or the types of industries that are very interested. Probably one of the key
things that is surrounding anything that we're doing is data, following the data.
Where is there a signiﬁcant amount of data that is either structured and/or isFINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 11 of 17Joe Mayer
Colette Kressunstructured, that could be leveraged to be more powerful and useful to the end
user, if you could apply the ability of deep learning training, which essentially just
says let the computer write the program to understand that overall information?
Those areas that we're seeing in rise [ph] from all of the diﬀerent applications that we
talked about at the hyperscales. But you can also see other industries where a large
amount of data -- ﬁnance, automotive -- you can see it also in high-end retailers that
are trying to process the amount of information, whether that be inventory or the
buying patterns to use that in terms of an AI manner.
So I think we're just going to see continuation of workloads expand and industries
expand. It's just too far to determine how fast or which ones will move forward.
But our focus has been endorsing and working with all of the diﬀerent types of
frameworks for deep learning that are out there, knowing which ones are the most
popular, knowing which ones are being trended towards certain workloads. And
making sure that we can empower that with additional code, additional libraries, self-
starting capabilities; so that we can get AI everywhere. And that's our approach.
{BIO 1470363 <GO>}
Great.
And thinking about this from the standpoint of kind of training, building the neural
network versus inference; deploying and using that in more of a real-time
environment -- it seems very clear that you guys are dominating at least the early
stages of training, both through instruction set, the CUDA instruction set is sort of a
de facto way of solving these problems. You also have the best graphics engine,
which certainly helps.
As you think about inference, do those natural advantages in training work their way
into the inference market? And what's the status of kind of going up to specialty?
Today, I think all that inference is happening on a CPU. Even Intel is saying there's
going to be a lot of specialty silicon used for inference applications. What's the GPU
prospects in that space?
{BIO 18297352 <GO>}
Yes. It's a really good question. Inference is not new, something that's been out there
for a while. And you're right, it's been dominated by CPU or could be anything from
a custom ASIC. But given the complexity of what that inference could be, you're
right, there's deﬁnitely an opportunity for GPU, with its work that it's done for
training, to also be deﬁnitely capable in terms of the inference phase [ph].
Our GPU today essentially is a really, really large, capable custom ASIC in that case,
that can do a lot of diﬀerent jobs at the same time in one complete architecture
together. We've built it for that purpose, because that is our core competency --FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 12 of 17Joe Mayer
Colette Kresspushing out high-end very capable custom ASIC is something that we're very good
at and will continue to do.
As we move forward, we'll move to where the high-end inference is going to be
necessary for GPU. Things that need voice command, things that need that voice
processing, is a prime example where a GPU may be very, very well suited for the
inference.
So it's a vast and wide market. And there's going to be many diﬀerent types of
inferencing solutions in terms of there. But a single-function low-end microprocessor
is probably not where we're going to be focusing on. We'll focus in terms of where
the high end is necessary.
{BIO 1470363 <GO>}
Okay. Great.
So I have one more datacenter question. And then I'll open to the audience. Then, if
we don't have questions, I'll move into autos and ﬁnancial stuﬀ.
You talked about DGX getting into a corporate environment. We've actually heard
our IT department working on GPU-related training projects. So it's happened kind
of faster than I would've thought, that you're sort of at least getting awareness in the
enterprise environment. Can you talk a little bit about that? And what are the things
you have to do diﬀerently when you're selling to an enterprise versus selling to
hyperscale?
{BIO 18297352 <GO>}
Yes. I think it's a good question.
Yes. The ﬁnance industry is very, very excited about the ability to work with DGXs and
get started quite quickly. Very sophisticated IT department. But it's a fast-starting
capability. Because it's essentially a containerized ability to start overall AI.
Moving faster than we expected? No. We just actually believed this is the way that
the enterprises would likely go to market and get excited about AI.
So what we had to do to prepare for that is our knowledge, our deep learning, our
knowledge of deep learning training and those frameworks. And put that into a box
that was essentially agnostic to whatever framework you wanted to do, is where we
concentrated on. And we're continuing to evolve that and even make it better and
better. But it allows them that quick start, by us taking on that part of that middleware
that they don't have to worry about. They can now worry about the application letter
(inaudible) they can worry about the data. And bring that in, too. Because we've
already started a signiﬁcant amount of that work.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 13 of 17Joe Mayer
Colette Kress
Joe Mayer
Unidentiﬁed Participant
Colette KressBut it also took us enabling working with those enterprises. Yes. We have
relationships from the high-performance computing. But there's a diﬀerent type of
market and diﬀerent types of users.
You've seen us in terms of our expansion of our sales force, our sales enabling. And
working with all of those diﬀerent enterprises. You've seen them, quite globally,
reaching out and spreading that word.
Additionally, we have many diﬀerent programs to continue to train enterprises on
how to do deep learning. We call it Deep Learning Institute. And the amount of
training hours, where people are like -- I just want to learn, how does deep learning
work -- and us using those training hours to teach enterprises how to do it.
Additionally, sure, the enterprises have the means to go oﬀ and purchase these high-
end systems. But we are also working with startups. There are many, many diﬀerent
AI startups, with what we're doing with an inception program, that allows them a
fresh start, with both helping on the cache side or on the hardware side, for them to
go get started in terms of those businesses.
So these are some of the things that we have done to continue to spread. It's not just
about building a piece of hardware. There's a signiﬁcant amount of software, there's
a signiﬁcant amount of socialization and training that we continue to do at the
enterprises.
{BIO 1470363 <GO>}
Yes, I took your CUDA for Dummies class at the Developers Conference in
Amsterdam. It was actually surprisingly easy to pick up. So I'd say --
{BIO 18297352 <GO>}
It was probably one of the biggest sold-out parts, other than the drink line (multiple
speakers).
{BIO 1470363 <GO>}
So let me stop there and see if we have questions from the audience.
Maybe you could just comment on inventory a little bit. I know there's elevated levels
on your balance sheet. Can you also comment how inventory sits at your gaming
partners. So the AIB [ph] guys like MSI, Gigabyte, Colorful, Pallet [ph]? How does that
compare to last year? And how happy were you with that inventory level?
{BIO 18297352 <GO>}FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 14 of 17Q - Unidentiﬁed Participant
A - Colette Kress
A - Joe MayerSure.
So our inventory levels take part of all of our diﬀerent architectures across all of our
diﬀerent businesses. Keep in mind most of our gaming inventory is related to our
Pascal architecture. And probably something about what we just launched in terms
of last night, in terms of our overall inventory getting ready, in terms of for that
launch and those pieces.
Keep in mind, in most of our gaming businesses, we are working on supplying the
overall chip to our adding card partners. But we also do a signiﬁcant amount of
kitting, where we actually kit the overall memory together with that. And that's part of
our practice. But a good part of our overall inventory is associated with a lot of our
high-end platforms as well.
What is unique and diﬀerent about our other markets outside of gaming is, in the
case of our Quadro workstations, as well as in our datacenter, we are selling multiple
years of our architecture. We are selling couplers. We are selling Maxwells. And we
are selling Pascals. So that is unique to the enterprise versus what you see normally
on the gaming.
So we are always keeping all of those diﬀerent things. Because we have to assure
that they have the capabilities to lock into an infrastructure that they have done and
continue to add onto those.
So our overall inventory really represents what we see in terms of our future sales, as
well as what we think we need in terms of supporting all of those diﬀerent
architectures.
Questions And Answers
And in terms of the inventory at your customers? Seems to be a recurring fear that
there's too much?
{BIO 18297352 <GO>}
Our customers would be our gamers. So I think (multiple speakers) but if we talked
about in terms of the channel colors, we have a good ability to see that worldwide.
We have very good market share. And we have a very, very healthy channel
relationship with it individually in those partners.
It is consistent with both the timing of the year, the timing around the diﬀerent
holidays that we had. And the timing in terms of what we had in terms of new
architectures. So we're comfortable with the overall channel levels that we have.
{BIO 1470363 <GO>}FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 15 of 17Q - Unidentiﬁed Participant
A - Colette Kress
Q - Unidentiﬁed Participant
A - Colette KressAny other questions from the audience?
Thank you.
Some of the large datacenter companies, companies that have datacenters -- like
Google, Facebook, Microsoft -- are rumored to be working on their own deep
learning chips, particularly Google. When that happens, how will that have eﬀects on
your own business?
{BIO 18297352 <GO>}
Yes. So it wouldn't surprise anybody that one would look to say, is this something
that we want to purchase, is this something that we could actually build ourselves?
There are always going to be pros and cons in terms of that. And there's not all the
same types of solutions out there. A lot of them have approach that says -- do I want
to build a custom ASIC for some of my pieces of inference or pieces of machine
learning? Now, that's a diﬀerent statement than -- do I want to build a complete
custom ASIC for deep learning training? Because that's a much, much harder, bigger
challenge to go oﬀ and do.
Keep in mind, the Company is very agile, such that we're generally coming out and
launching something quite often. And we're going to keep you quite on your toes in
terms of our capability to move that quite fast. So sometimes, the same time that
they may process overnight, that they think they want to come out with something
custom, we may be in market the next day with something. And that's got to be
something that they overall balance.
There's a lot of diﬀerent ways to solve some of those inference problems, solve
some of the machine learnings or some of the more simpler types of data problems,
versus the capability in the performance that you have with the GPU is really, really
hard to substitute that. Because you do destroy a signiﬁcant amount of that value in
the gain that you got in terms of time and TCO, by leveraging an overall GPU.
So it won't surprise us. But it's not going to necessarily change what we believe is a
very vast market and a very large market that a GPU will be here. And there may also
be instances where a custom ASIC may be there as well.
Can you sort of compare and contrast what you see from hyperscale relative to
traditional enterprise? Is this something that is particular relevant for hyperscale
customers but maybe not so much relevant for the traditional enterprise? So what
are you seeing there?
{BIO 18297352 <GO>}FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 16 of 17A - Joe Mayer
Q - Unidentiﬁed Participant
A - Colette Kress
Q - Unidentiﬁed Participant
A - Colette Kress
Q - Unidentiﬁed Participant
A - Colette KressYes. I mean, it's a good question that says -- would an enterprise look at building
something their own? That's going to be challenging, because you're looking for
that talent to actually build that. It's actually not a short process. Keep in mind, when
you think about NVIDIA and what we have, we have thousands and thousands of
developers whose only focus is a GPU. That's all they do for a living. That's all they've
done their entire careers. So we probably have the largest workforce associated with
building out that design than anything else in the world.
So I don't think we see that as being a large thing of what enterprises would do.
Because we're already seeing right now that fulﬁlling it with a DGX, which is a
container type approach. And/or leveraging the cloud, is meeting a signiﬁcant
amount of the current demand and where they want to go. It's not necessarily where
the AIs have approached their overall IT. It's still early to say where that will be. But I
think you're correct that if you have the means, if you can get that talent, if you can
justify the overall time to market, your ability to outperform something that would be
commercially available from us, that might be something that you might look at. But
it still may not meet the exact needs of what the high-end GPUs are doing right now.
{BIO 1470363 <GO>}
Time for one more quick one.
Quick question on -- so basically, is it the barrier to further increase processing
power is the bandwidth to memory? So can you talk about, is there something that
NVIDIA looking to do in the next couple of years to further improve that? And also,
can you comment quickly on the longer term, like three; or ﬁve-year outlook, on
both gaming and datacenter demand for GPUs? Thanks.
{BIO 18297352 <GO>}
(multiple speakers). The last half -- I'm sorry -- of your question was on the gaming
and datacenter --
And datacenter demand for GPU, that CAGR and [ph] mix through ﬁve-year.
Anything --
{BIO 18297352 <GO>}
So long-term growth rate?
Long-term growth rate.
{BIO 18297352 <GO>}
Sure. We could just go [ph], just hit long terms of that one.FINAL TRANSCRIPT 2017-03-01
NVIDIA Corp (NVDA US Equity)
Page 17 of 17A - Joe MayerLet me take the ﬁrst part of your question ﬁrst in terms of memory. It's essentially a
question about scale out or scale up. And depending on your workload, both of
those are going to matter, in terms of do I put together more, or do I just want to get
the overall scale to go consistently on the memory. There's always continued work
that we are doing in terms of the architecture, both with the overall bus and express
between the memory and the overall GPU, as well as more of what we can do in
terms of just the core architecture of the hardware chip.
Right now, it has not been a challenge in terms of the memory. But we'll continue to
work on that. In many workloads, it's not even close an issue, because of where they
see the overall needs.
So the long term, in terms of gaming and datacenter -- if I had my little crystal ball, it
would be a lovely piece. But it's hard to say. Again, these businesses are very healthy.
The drivers that inﬂuenced us last year are still here. They didn't go away when we
changed the clock and moved to 2017. What that overall growth rate and the speed
of that growth is just really hard for us to say.
{BIO 1470363 <GO>}
Colette, thank you very much, it's very helpful.
This transcript may not be 100 percent accurate and may contain misspellings and 
other inaccuracies. This transcript is provided "as is", without express or implied 
warranties of any kind. Bloomberg retains all rights to this transcript and provides it 
solely for your personal, non-commercial use. Bloomberg, its suppliers and third-
party agents shall have no liability for errors in this transcript or for lost proﬁts, losses, 
or direct, indirect, incidental, consequential, special or punitive damages in 
connection with the furnishing, performance or use of such transcript. Neither the 
information nor any opinion expressed in this transcript constitutes a solicitation of 
the purchase or sale of securities or commodities. Any opinion expressed in the 
transcript does not necessarily reﬂect the views of Bloomberg LP. © COPYRIGHT 
2024, BLOOMBERG LP. All rights reserved. Any reproduction, redistribution or 
retransmission is expressly prohibited.