FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 1 of 14, Analyst
, Chief Financial Oﬃcer & Executive Vice President
Atif Malik
Q - Atif Malik
A - Colette M. KressCiti Global TMT West Conference
Company Participants
Atif Malik
Colette M. Kress
MANAGEMENT DISCUSSION SECTION
{BIO 15866921 <GO>}
My name is Atif Malik, I cover semiconductor equipment and specialty
semiconductor names at Citi. It's my pleasure to welcome Colette Kress, CFO,
NVIDIA; also Shawn Simmons from Investor Relations today. It's a ﬁreside chat
format, I'll start with my own questions and then I'll open it up for your questions.
Q&A
{BIO 15866921 <GO>}
Colette, I'm going to start with autos, it's the smallest percentage of your revenues,
but because it's CES and all the buzz is around self-driving cars, I'll have to start with
autos. You guys have announced many partnerships, your partnerships went from
200 last year to 320 plus, DRIVE Xavier is sampling right now. It appears you guys
have two plus years of lead over competition. Can you just map for us how do you
see your auto revenues grow in terms of your Level 3, Level 4, Level 5 over the next
three years, how does that opportunity grow for you?
{BIO 18297352 <GO>}
Okay. So a good question. But let me probably step back just a little bit and let's talk
about our goals here about at CES in terms of our press conference, what we wanted
to convey. We – our overall strategy is really regarding self-driving cars in terms of
auto. We've been in the auto business for more than 10, 12 years focused in terms of
helping the technology within the car, primarily focused in terms of video displays
for essentially the infotainment systems that you see in many of the high-end cars.
We are still and that is still a very important part of our revenue base in terms of what
we're doing. But several years ago, we shifted to our work in terms of what we had
seen in terms of the datacenter that we felt we could help in terms of autonomous
driving and self-driving cars. If you look back in terms of the thought process of
when self-driving cars would probably hit the road, I would say, earlier, it was like a
20 – 30 type of timeframe; 10,15 types of years out.
But actually using some of the techniques that we have learned in the datacenter
regarding artiﬁcial intelligence, we were able to actually assist many of the OEMs onFINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 2 of 14Q - Atif Malikhow they were thinking about self-driving cars. When we're here today at CES and
watching, probably, the last four or ﬁve years, we've moved quite tremendously in
terms of the understanding with the OEMs of the importance of looking at diﬀerent
types of techniques to solve this problem. And many of them are looking at
supercomputers and/or looking at very, very complex processors to solve this.
So, one of the things that we did is we announced the availability, as you mentioned,
in terms of Xavier. So, Xavier is our SoC that will be in terms of a form factor that can
go in our Level 3, Level 4s, and Level 5 autonomous driving cars going forward. We
are seeding this with customers now that they can start working on it. It is both – can
be used in terms of in the development phases, but very importantly, also in terms of
into production types of cars.
We've got it to a form factor in terms of that it can be integrated with all of the other
parts of the car. We've also reached, in terms of a overall performance level and
energy eﬃciency, that will be ﬁne-tuned and perfect now for using in terms of those
cars, it's about 30 watts. It's about 10x improvement in terms of energy eﬃciency
from our prior version. And I think the most important part that you had mentioned
was it about two years ahead of probably any competition. Meaning customers now
have this today that they can start developing. We all know the long cycles that are
there in terms of automotive and our goal was to make sure that we could provide
that to automotive and they could get to their timelines, which is approximately
2020 or 2021 in terms of when we'll see self-driving cars coming through.
So, with that in some of our partnerships, we work with more than 320 diﬀerent
OEMs, startups and tier 1s. It's important to understand that all of those organizations
are very important in terms of this transformation of the overall transportation
industry.
Now, when it comes down to determining these partnerships and where they move
in terms of development agreements and they move to overall productions with the
car, it's still little bit early to actually see that through. We'll be seeing our
infotainment systems continue to ride for the next several years. We announced
agreements as well to inﬂuence in terms of AI inside of the car. So, probably doing
more in terms of what we have with our infotainment systems with Daimler and with
others in terms of focusing on internal AI in the car; voice recognition, gesture
recognition for the driver as well as for the passenger. So, what you'll see is
infotainment continue to run about where we're seeing the overall automotive
industry run and we'll probably see development agreements along the way with
production probably still looking in in terms of calendar 2020 or calendar 2021. It's
just diﬃcult to say the size in terms of that until we get a little bit closer.
{BIO 15866921 <GO>}
Okay. At GTC Japan in December last year, you guys announced a partnership with
Pioneer to combine 3D-LiDAR within an NVIDIA DRIVE platform. Is it beneﬁt to
NVIDIA platform to partner with speciﬁc technology partners or to be agnostic or
allow the automotive partners to be able to use their peripheral preference of
technology?FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 3 of 14A - Colette M. Kress
Q - Atif Malik
A - Colette M. Kress
Q - Atif Malik{BIO 18297352 <GO>}
Yeah. So, it's an actually interesting world in terms of the automotive and the amount
of partners that take part in terms of building a car. A car is tremendously complex. It
works with a signiﬁcant amount of vendors and partners to build every single part of
that. Our approach whether it be in terms of in the datacenter and/or in automotive
is to pretty much be a conduit to any types of relationships or any types of work that
the auto manufacturer wants to do.
We have been generally agnostic. And agnostic in terms of operating systems,
partners that they want to use, with an overall board that can be a hardware and
software fully stacked and ready to go. But you're right, we can take input from lidar,
sensors, cameras, any types and any type of diﬀerent vendors. We actually really
don't determine any one of them as more important. It's really up to the OEM to say.
But these partnerships are important in terms of understanding the integration,
understanding the regionalizing of self-driving cars. Self-driving cars is not, we can
make one car for the entire world. It's very important to understand the dynamics in
Japan or the dynamics in China, of course, as well as in terms of here in the U.S. So,
you will see those partnerships that we are getting a good understanding. They are
understanding our platform, we are understanding with theirs about (07:18).
{BIO 15866921 <GO>}
Great. Jensen has commented in the past that the future of autonomous vehicles is
surely a software-deﬁned car. We had Renesas here yesterday and they were trying
to make a point that the car industry is diﬀerent from a PC or a server industry, where
NVIDIA has had a lot of experience in the past. Can you help us understand how
already entrenched players like the Renesas in the auto market for infotainment and
other areas are positioned versus your compute-intensive software approach (07:54)
{BIO 18297352 <GO>}
So, it is solving these large feat in front of us in terms of self-driving car is not
something that, at one point, we're going to say we're complete, and sometimes
when you're shipping things like a PC, it ships, it's ﬁne, it's complete, all the
hardware is incorporated. We will constantly see continued upgrades, continued
learning, continued new features along the way in terms of that software. What we
do understand, which is also quite complex, is the amount of the importance on
safety that the OEMs will take in terms of thinking about this.
The safety is crucial, 100% in terms of the software that we're writing. So, we agree
that it absolutely is very diﬀerent than what we've seen in terms of hardware. But
working together with the OEM and our understanding in terms of the data and the
use of artiﬁcial intelligence, we do believe we can get to something quite solid by
those timeframes and it will probably continue to improve for many, many, many
years in terms of what will be developed.
{BIO 15866921 <GO>}FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 4 of 14A - Colette M. Kress
Q - Atif MalikOkay. As a CFO, I'm curious to know how you're juggling with your R&D prioritization
across gaming and datacenter, and auto especially because it's going to be such a
big market. I know you guys have a common platform, there is Volta and – but how
are you prioritizing R&D resources for the auto opportunity?
{BIO 18297352 <GO>}
Yeah. So, we have a unique model at NVIDIA. The reality is we have one product, we
make GPUs, and what is unique is the exact same technology that gamers use to
watch games or play games is the same technology that we will put inside of a car.
How does that work? It is a processor that is able to span many, many diﬀerent types
of use cases. It could be done for visual display of graphics, just because of that
processor able to process a signiﬁcant amount of graphics as well as what we need
in terms of automotive, which would be the overall compute capacity to process all
the data.
So, when we established a uniﬁed architecture is what we refer it to, across all of
those GPUs, they're all diﬀerent GPUs, but they all have the same underlying
architecture. That allows us to really leverage our R&D workforce quite eﬀectively.
Because anybody else that would have to do that would have to completely rebuild
an overall team if we didn't have that uniﬁed architecture.
So then what happens is, we will continue to try and establish both the middleware,
the overall programming language is also the same, across all those GPUs. You've
heard us talk about CUDA. CUDA is our development platform that we use. And then
after that, we establish key software needs for each one of those industries. And
many times, we're supporting multiple operating systems relatively agnostic to any
one operating system. And then, we will go where there are key industry needs such
as automotive and really focus there in terms of the software work that needs to be
done.
In the case of automotive, there's a little bit more in terms of the hardware to make it
foolproof for working inside of a car. It's got to exist for as long as that car may be on
the road, but it also needs to exist in many extreme conditions of hot and/or cold, or
other adverse weather.
So, our allocation is a uniﬁed approach which allows us to, from a basic service (11:47)
like GPU, and you're right, we are making investments in terms of in the datacenter,
in artiﬁcial intelligence, hiring very strong engineering staﬀ that can help us in terms
of most of this industry areas that we're going into.
{BIO 15866921 <GO>}
Great. I want to move on to gaming. You guys announced MAXQ, a lightweight
gaming laptop that has 2x that the capability of a desktop . And I want to understand
is that the direction the market is moving towards where the gaming or the
enthusiasts are – they want portability, they want to have a lightweight notebook and
yet your competitors are trying to join hands to take some shade away from you. Can
you just talk about those dynamics as well?FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 5 of 14A - Colette M. Kress
Q - Atif Malik
A - Colette M. Kress{BIO 18297352 <GO>}
Yeah. So, what we have seen is others tending to continue to be a mobility of how
we work, as we see across the room everybody brought something that they could
write with in terms of mobility. But what we also don't want to give up is in terms of
the thin and light. Carrying around a 10-pound overall PC or grabbing an airplane
seat for your PC is just not exactly what people want to do.
So, what we try to do was accomplish both. That says they are still looking for the
high-end graphics, but they still want their thin and light at the same time. We've
now been able to, with our overall notebooks get to the exact same performance
that you could receive in a full desktop in a mobile form factor. It also allows those
that didn't want a separate and only dedicated PC for gaming that you have
something that could do both and accomplish that. Also very popular in terms of
those that are going back to college. I need to write my term paper and then I also
have something in terms of the gaming.
So, we see this as a very big and important industry. Many of the OEMs have also
created gaming notebooks that are – the glowing keyboards, the other great things
that you would want in terms of your gaming notebook to do. So, we see this as a
next-gen in terms of industry, in terms of where things will go. We do see that
mobility is the next movement. But what it does is, sometimes in the U.S., it is a
duplicative, meaning they will probably also have their desktop and they will also
have a mobile form factor.
Now, competition also looking at that as an option whether they could come to
market. But again we are starting with a tremendous Pascal architecture in terms of
our gaming and our high-end. So, we are meeting the needs of gamers with that
high-end GPU. They still have to accomplish that from a competition standpoint to
make sure that they are meeting that need within that thin and light in terms of a
great GPU. So, we'll see how that goes.
{BIO 15866921 <GO>}
Great. How should we think about the launch of timing of Volta platform for gaming
given typically you refresh a platform in two, two and a half years and maybe its
manufacturing -the problem will be that the size of the Volta is too big, but how
should we think about the timing of Volta for gaming?
{BIO 18297352 <GO>}
Yeah. So we don't generally announce our consumer products ahead. We do like to
surprise our customers, so deﬁnitely stay tuned. But yes you are correct that on
average over a period of time, we have refreshed our consumer mind about two and
a half years or so give or take. We have launched and we haven't reached the two
year mark in terms of Pascal yet. It is still selling strong. Holiday season was ﬁlled with
great games and we'll talk about that in terms of earnings and when it comes in
terms of February.FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 6 of 14Q - Atif Malik
A - Colette M. Kress
Q - Atif Malik
A - Colette M. Kress{BIO 15866921 <GO>}
Okay. There is considerable debate among investors and the use of GPUs for mining
cryptocurrencies and crypto's impact to the gaming demand in the future as well as
an incremental demand for you guys above gaming. I mean, what are your views on
cryptocurrency mining demand longer-term and what steps has NVIDIA taken to
avoid any kind of cannibalization between the two markets?
{BIO 18297352 <GO>}
Sure. So cryptocurrency is a unique area having what we refer to as market dynamics.
A diﬀerent statement than saying that we believe it's a market. It has risen quite
quickly. It started probably originally way back with the Bitcoin in 2014, but if you
recall the Bitcoin moved quite quickly to a custom ASIC.
Right now, we are dealing with currencies, one of the most popular one is Ethereum,
which has increased in terms of valuation. The higher the valuation, the more that the
overall miners are willing to purchase high-end GPUs. What we did in order to
address that market is we came through with what we call custom mining boards
that are not available or not available to do gaming but are really just for overall
mining. They are at a great price point in terms of the overall return on investment
that miners can experience is there for them and we are – have been selling that and
we do communicate each quarter in terms of the size of what we're seeing in terms
of the mining.
The challenge that we have is it's not a market that is relatively stable. It comes and
goes with the overall valuations. So, valuations aren't necessarily clear in terms of
some of those pieces that are driving it either. But what we can do though as a GPU
company is we can address that market because we can quite easily come up with a
GPU that would be tailored for the overall market. And we'll continue to do that but
it doesn't change our focus, our strategy as a company that's focused on we ensure
that our gamers have GPUs focusing in terms of artiﬁcial intelligence in the
datacenter as well as automotive.
{BIO 15866921 <GO>}
On the datacenter side. Curious how your momentum with Volta is going on the
inference side. You guys had a nice last quarter where you were able to ﬁll in the
pipeline for your customers. How do you guys feel about the momentum on the – for
the Volta for inferencing?
{BIO 18297352 <GO>}
Yeah. The Volta demand, we had launched Volta at our GTC back in May of last year.
Within that quarter, we were able to, from a launching, get to solid yields, establish
them with customers and give samples to them. So when we started in terms of the
beginning of Q3, we were in full production. We were extremely pleased with the
speed of that. As we all know, Volta is the largest microprocessor on the planet. It is
probably a very, very, very complex engineered piece that it was established.FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 7 of 14Q - Atif Malik
A - Colette M. Kress
Q - Atif Malik
A - Colette M. Kress
Q - Atif Malik
A - Colette M. KressSo, we've continued to work with many customers. Most of the hyperscales and the
CSPs have come out verbally indicating they will use overall Volta. And what we're
working on in terms of is that process called qualiﬁcation. The CSPs, the hyperscales,
do have to qualify that for their environments whether that environment is their
cloud environments, whether that is for internal use. So we're very pleased with both
the acceptance and excitement around Volta and we've deﬁnitely sold. It's becoming
a material part of our overall datacenter business. And we'll still probably see that
continue going forward.
{BIO 15866921 <GO>}
Okay and I'll stop here and see if the audience have questions. If you have a
question, press the push button in front of you before you ask your question. Any
questions?
It's pretty impressive, the trillions of operations you can do in the next-generation,
but I don't have a good sense for what exactly that means. So, if your nearest
competitor can do one-tenth of that, what does that actually mean in the ability to
self-drive a car, how many are required? Maybe you could just get into some of the
speciﬁcs or the specs that are required.
{BIO 18297352 <GO>}
So, in terms of that very beginning part, in terms of one-tenth the amount of
processing power...
{BIO 15866921 <GO>}
Processing power, exactly.
{BIO 18297352 <GO>}
Right.
{BIO 15866921 <GO>}
And I know there is a trade-oﬀ of wattage and things like that, but I'll just stick to the
processing power.
{BIO 18297352 <GO>}
Yeah. So, a really good question. So, when you think about a self-driven car or if you
think about yourself driving behind a wheel, and honestly what you are using in
terms of all your sensors to drive that car, both from a visual standpoint, what you're
hearing, what you're seeing, and what you are inferring for the many years of your
driving capabilities. What you are trying to do in terms of the self-driving car is
duplicate that. There's no handbook that any of us read in terms of how to drive a
car. So, in order for a car to drive at 60 miles an hour, it has in a signiﬁcant amount of
data that is coming into the car that it needs to compute in real time to understand
that.FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 8 of 14Q - Atif Malik
A - Colette M. KressThe ﬁrst, probably the most important piece in terms of self-driving cars is high-
deﬁnition maps. These are diﬀerent than the maps that you and I use every day to
get to ﬁnd the nearest Starbucks. These are high-deﬁnition maps that are down to
the overall centimeters. Because, essentially, that's what a car has to be able to drive
in terms of its route. High-deﬁnition maps, new information coming in from cameras,
coming in from sensors, lidars or other types of things is a signiﬁcant amount of data.
If you are only one-tenth the ability of an overall GPU, you're not going to be able to
process that data. The car is driving, you wouldn't be able to process the data to
come up with the solutions in how to move (21:40).
This, several years ago, became very apparent to many of the OEMs as they sat there
and said, I need more compute. Many of the cars that you see driving around that
may not look visually pretty because they've got cameras all over them, they've got
things stuck on them, most of them have supercomputers, PCs, GPUs in their trunks,
so that they're able to capture all of that diﬀerent data. So, it's a little bit of a
misnomer that people think that all of a sudden we can move to a simple
microprocessor inside of the car for autonomous driving. It's just, it's a very, very,
very hard problem in terms of what we're doing.
Now, our work in terms of auto manufacturers stems all the way back to the
datacenter to the production car. What we mean by that is we are gathering data on
the road, we are gathering the maps on the road, we are working with them in their
datacenter with our GPUs from our datacenter business or our DGX supercomputers
for them to process that data right over all algorithms. What will happen is that
information will be fused onto a Xavier overall platform that will be inside of the car.
And then, additional incremental information that may happen as you are driving will
be processed and used against the overall information that you had from the
datacenter to decide what the right road would be.
An example, you're driving down the freeway and all of a sudden there is a set of
cones at the ramp that you're supposed to take as an exit. You have to process at
that time new information, what should we do? We'd refer to that as an inferencing
state of do I continue, do I go around the cones, do I go to the next exit, for
example? So, it's quite complex. I know the human brain just drives and it seems
quite easy, but to actually move that, it's actually a very signiﬁcant amount of data. I
hope that helps.
{BIO 15866921 <GO>}
With the security issue with an Intel chip, which kind of impact do you see for NVIDIA
in the long-term across the GPU?
{BIO 18297352 <GO>}
Yeah. So the industry is facing a change that it needs to do to the overall CPUs that
are out there. It came out earlier last week in terms of that challenge. Essentially, a
CPU with its serial processing, when it doesn't have a set of instructions, could
possibly infer in terms of the next step to keep the serial processing. That created the
security hole for it. I think the industry is very aware that: one, we need to patch thisFINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 9 of 14Q - Atif Malik
A - Colette M. Kressquite quickly, it is a very, very big feat in terms of the amount of devices that are out
there from a CPU standpoint.
A GPU is not impacted in that matter. It is architected diﬀerently. It doesn't have that
same piece. We will be helping in terms of with our drivers, helping patch at the
actual CPU level. But no, our GPUs are not aﬀected. SoCs, which stands for systems
on a chip, which is the merge of a GPU and a CPU together, could be aﬀected and
there will be some patching in terms of that area as well. Again, industry-wide, all
focused still a little bit early to tell. But again, I think the industry will solve this quite
quickly as we move forward.
{BIO 15866921 <GO>}
Questions?
Yes. Good morning. A question on the timing of the mass market for artiﬁcial
intelligence. At that time like three years down the road, do you believe that GPU is
going to be the technical support for mass market artiﬁcial intelligence or do you
believe that the Google or Amazon that seems to prepare some step can develop
alternative technologies for that?
{BIO 18297352 <GO>}
So, when we think about the mass market of self-driving cars, what we are seeing
right now is because it is such a large change to the transportation industry, new
areas for diﬀerent people to focus on have started. For example, you've heard over
the last several months, the discussion in terms of robo-taxis. Where, probably, in
conﬁned areas, conﬁned communities, you will actually have fully self-driving cars, or
nearing the (26:18) Level 5 to do that where there is no driver.
You could think about this in terms of university campuses. You could think about
this in terms of a certain square mile of a downtown that they would have that.
Additionally, you ﬁnd areas where self-driving cars will be functional in terms of
freeway driving. I know it sounds odd, but it's actually easier to build self-driving car
capabilities for freeway driving than it is to in terms of in overall residential.
So, our goal is not to say that we'll be in a mass market or we will be in all diﬀerent
types of platforms because of the complexity across the world in terms of the types
of cars and the type of transportation that is existing is wide. Now, the examples that
you gave are interesting, but there is still a need to have the underlying compute.
The underlying supercomputer is still very, very key no matter who decides and
works in terms of there (27:22).
There's a role probably for many diﬀerent types of companies inside of the car, but
our focus is going to be the underlying platform and they – all those companies
could continue to use our platform as they do in the datacenter and/or use in terms
of the work that they're doing in terms of cars, or they could ﬁnd another very high-
end in terms of overall processor. The challenges that we're quite many years ahead,
many of the others in terms of the processor. So, we're probably going to beFINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 10 of 14Q - Atif Malik
A - Colette M. Kress
Q - Atif Malikworking with many over the next couple of years. But you're right, there deﬁnitely
can be others that could enter this market.
{BIO 15866921 <GO>}
Questions. Colette, you talk about the impact of the tax reform on capital allocation
in oﬀshore, onshore cash and also your appetite for M&A? We have seen a ﬂurry of
announcements of partnerships with – on semiconductor, with Maxim. On the DRIVE
functional safety architecture, you partnered with BlackBerry and DTEK (28:34). I
mean is there a need for the company to get a little bit more aggressive in terms of
M&A?
{BIO 18297352 <GO>}
So tax reform is aﬀecting so many of us as we work through the end of our calendar
year – end of our ﬁscal year. When we are working right now, we're really trying to
understand the impacts of that. Understand the right accounting that we'll go
through to both tax or international cash and understand what our rate would be
going forward.
We generally look at this to be overall neutral and positive to us, but we'll have more
in terms of February. But what that means from an overall use of cash, most
companies are now to the point where they don't have an allocation of that's my U.S.
cash, that's my international cash and I can't touch my international cash – excuse me
– in the same manner.
So it's actually nice to see that we won't have the overall trapped cash, but it still
allows us to focus on what our key uses of cash are. Our number one use of cash is
investment back into the business. That investment back into the business is
supporting many of these large markets in front of us. It is the hiring, but it also is the
hiring and supporting the overall infrastructure that is necessary for the – for that
hiring. Their overall computing that they use whether that be cloud computing or
whether they use on-hand computing, but also in terms of facilities and those things.
Our second focus is looking in terms of M&A. We are constantly looking. But you're
correct, the company has been mostly in terms of small tuck-ins, smaller medium
types of things. And we've been generally mostly organic but we will continue to
look to ﬁnd some of those right opportunities that we could add.
And then thirdly, our capital return program. It wasn't a one year thing. It has
continued for many years and we'll continue to have that as our focus. So, the cash is
not as trapped. But again, our principles in terms of use of cash are still solid.
{BIO 15866921 <GO>}
Great. And one question I get asked frequently by investors is about the supply of –
from processors or from your foundry partners like with TSMC and Siemen. How do
you guys feel about foundry wafer supply being able to meet your demand as well
as graphics and beyond?FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 11 of 14A - Colette M. Kress
Q - Atif Malik
A - Colette M. Kress
Q - Atif Malik{BIO 18297352 <GO>}
Yeah. So we have been working with one foundry partner for many, many years. So
we've established an extremely good relationship in terms of when we say, we think
demand is this and we're looking for an allocation, I think we have their ears and
eyes open in terms of what we're looking for.
We also have a partnership with Samsung in terms of foundries as well. So I think we
feel very solid in terms of that process and assuring that we have the right – both
supply and right demand work through. The best that we can do is focus on
understanding our demand and giving them as much as heads up as possible. But
right now, things are moving quite well.
{BIO 15866921 <GO>}
Okay. Back in May last year at your Analyst Day, you guys talked about a $30-billion
datacenter opportunity with inference at $15 billion; training, $11 billion; and high
performance computing, $4 billion by 2020. Training, here's not much debate out
there. GPU is the workhorse for training and you guys have high market share there.
But in the inference market, what is a bull (32:11) in a base case scenario for your
share aspirations or in terms of how much of the market you can grab?
{BIO 18297352 <GO>}
Yeah. As the numbers show, we do believe inferencing is a very, very large market.
And it's actually a very complex market and there is a lot of diﬀerent types of
inferencing that is occurring across the world. And not all inferencing is going to be
for us. Thinking about inserting a chip inside of a thermostat, inside of a toaster is
probably not where we feel we would be in the best use.
But thinking about the complexity of inferencing that will exist because of the growth
of AI, we have a great opportunity for there. We've already seeded a signiﬁcant
amount of our work with about 1,200 diﬀerent customers that are testing in terms of
the overall inferencing capabilities with the work they're doing. We are well aware
that this has primarily been a CPU market. And in some cases, it will still exist as a
CPU market. But there's a market there for us when we have now established more
complexity and more challenges in terms of computing to use a GPU in its parallel
processing to get more types of images per second, completed during that
inferencing stage.
If you think about it, the overall automotive and the platform inside of the car is a
prime example of inferencing where you will be doing artiﬁcial intelligence, at the
same time you'll be infusing a signiﬁcant amount of data on time. And we feel we are
best engineered at that time to do so. So, no, it's not a path that says there's a certain
market share that we think we can capture, but it is a great opportunity for us
because we're starting at zero to move up and capture any part of that very, very
large market.
{BIO 15866921 <GO>}FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 12 of 14A - Colette M. Kress
Q - Atif Malik
A - Colette M. KressGreat. Let me see if there are any further questions in the audience.
So you announced you have 320 partnerships, congrats. Let's say, what value does
the 321st bring to NVIDIA and then what value do you bring to the 321st partner?
{BIO 18297352 <GO>}
Yeah. So, the partnerships are an important part for them to continue working with
our overall platform. Those partnerships are not always in terms of a contractual
obligation in any manner. But what we've done is we've been able to seed our
overall platform, helping understand what they are bringing to the table, and their
understanding of autonomous driving. Every single one of our partners that we work
with, we learn something from. In the same way, they learn from us in terms of the
value of artiﬁcial intelligence in the platform and what can that bring. The more
evolving in terms of the ecosystem and people working together, the sooner we're
going to solve that problem.
So those are the purposes of the overall partnerships. But a lot of it has been
centered around our underlying DRIVE PX platform; seeding that, getting them to
use it, giving us feedback, giving that data and that information all collectively put
together. So it's been both eﬀective for the work that they're doing as well as the
work that we're doing.
{BIO 15866921 <GO>}
Yes, your question.
How do you think about what the long-term split in AI chip is between ASICs and a
company like NVIDIA that basically just makes a standardized chip for every
application? I mean, it seems like there will be some balance (36:12) there, but how
do we, as investors, think about what that is?
{BIO 18297352 <GO>}
Yeah. So a lot of discussion that says, a overall GPU can serve a lot of diﬀerent
functions and spanning across. There's discussion and we actually see several saying,
but we might be able to get a better performance with an overall custom ASIC for
certain workloads. And that's a constant theme that you hear. I can get a custom
ASIC for certain workloads for certain scenarios et cetera. Is that better than an
overall GPU? I think that depends.
One, it's challenging to bring any type of custom ASIC or any type of custom chip
overall to market. We've seen folks do it, spend several years doing it. And the reality
is that a GPU comes out on a cadence quite often. It has been engineered for
improved performance almost every single time, including more features and it has
a ability to dazzle more than 650,000 developers that are out there. So, although
some may say, I bet you if I customize something, I can get a little bit more. You still
have an investment over that period of time which is signiﬁcant to reach that silicon
(37:40), you have an investment in terms of how do you establish the software andFINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 13 of 14Q - Atif Malik
A - Colette M. Kresspieces of that, but at the same time we'll be coming out something with the cadence
that already beats in terms of value.
So it may be really, really early. It may never actually move in that direction or we may
see cases for very, very speciﬁc workloads. Our goal is democratizing AI. To put it in
hands as quickly as possible, probably 10, 15 years ago you would have approached
this in a diﬀerent manner. IT organizations would build out clusters in terms of their
datacenters and start working on that.
If you think about our availability of instances in the cloud with service providers or
buying a DGX supercomputer from us that all you have to do is plug it in and it's
already containerized or starting in Tesla or easing the use of moving into the AI
which will hopefully draw the adoption of AI as fast as possible. But we do realize
that the world of AI is extremely big market, but our overall goal is to just seed as fast
as we can AI, so we can solve some extremely hard problems and use a lot of that
data that's out there that is still on top.
{BIO 15866921 <GO>}
Yeah.
I'm not sure if this is going through. But – can you hear me? So, the auto business,
you guys let – made a lot of great announcements this weekend. How big is auto
now as a percent of your overall revenue? And how big is it going to be two years
from now, ﬁve years from now assuming the rest of the business continues to grow
the way the rest of business continues to grow. Obviously, that's an assumption but
how much – how big a business should we really think about this or is it sort of you
know 20 years out kind of thing.
{BIO 18297352 <GO>}
Yeah. So, currently, our automotive business of course is under 10% of our overall
revenue today. We have some very fast growing businesses. Automotive has also
had a great history in terms of growth as we rolled out in terms of infotainment
systems. It's early to say in terms of how big it will become as a part of our overall
company, because it is a long play dealing with autonomous driving, but if you think
about the overall growth of the company's over 30% growth rate, 30% to 40% this
last year.
We've had some businesses that have doubled. We have said some businesses that
have grown more than 25%, our gaming, our datacenter and our automotive are
three very, very strong strategic focus of ours. Huge market caps, market
opportunities in front of them. So, that's something that we're going to continue to
invest. How fast each one of them realize those market opportunities? It is still
unclear. As we know in terms of self-driving cars, it is a couple years out in terms of
production, in terms of what we'll see. So, we'll just have to see through that period.
But we do believe it's an important area because of the massive transformation that
will happen with transportation.FINAL TRANSCRIPT 2018-01-10
NVIDIA Corp (NVDA US Equity)
Page 14 of 14We're out of time. Thank you, Colette and NVIDIA for coming to the Citi TMT West
Conference.
This transcript may not be 100 percent accurate and may contain misspellings and 
other inaccuracies. This transcript is provided "as is", without express or implied 
warranties of any kind. Bloomberg retains all rights to this transcript and provides it 
solely for your personal, non-commercial use. Bloomberg, its suppliers and third-
party agents shall have no liability for errors in this transcript or for lost proﬁts, losses, 
or direct, indirect, incidental, consequential, special or punitive damages in 
connection with the furnishing, performance or use of such transcript. Neither the 
information nor any opinion expressed in this transcript constitutes a solicitation of 
the purchase or sale of securities or commodities. Any opinion expressed in the 
transcript does not necessarily reﬂect the views of Bloomberg LP. © COPYRIGHT 
2024, BLOOMBERG LP. All rights reserved. Any reproduction, redistribution or 
retransmission is expressly prohibited.