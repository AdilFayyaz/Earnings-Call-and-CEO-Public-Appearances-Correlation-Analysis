FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 1 of 14, Executive Vice President and Chief Financial Oﬃcer
, Wells Fargo
Colette Kress
Aaron Rakers
Colette Kress
Aaron RakersWells Fargo 7th Annual TMT Summit
Company Participants
Colette Kress
Other Participants
Aaron Rakers
Presentation
{BIO 18297352 <GO>}
So, is our skin green?
{BIO 6649630 <GO>}
I'm sorry?
{BIO 18297352 <GO>}
Is our skin green?
{BIO 6649630 <GO>}
Yeah, maybe. I don't know. We'll ﬁnd out afterwards, huh? All right. So, why don't we
go ahead and get started? I'm Aaron Rakers. I'm the Semiconductor and Hardware
Analyst here at Wells Fargo, and extremely excited to host a discussion with Colette
Kress, the CFO of NVIDIA.
Before I start, though, Colette, I'm just going to throw out this little fact, right? You've
been here 10 years. Actually, September was your 10-year anniversary.
At the point you joined, the company was doing $4 billion of revenue trailing 12
months. You're now doing $45 billion, roughly, right? The market cap's gone from $9
billion to $1.2 trillion. So, I'm going to start by just saying, good work. Congrats. It's
been a phenomenal run. So, keep it going. Don't take your foot oﬀ the pedal.
But before I start with the questions, Collette, I think you get the joy of reading the
safe harbor, and then I think you might have some prepared comments as well. I'll
kick it over to you.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 2 of 14Colette Kress{BIO 18297352 <GO>}
Sounds great. Thank you, Aaron, for having us. I do have an opening statement, let
me ﬁrst say.
As a reminder, this presentation contains forward-looking statements, and investors
are advised to read our report ﬁled with the SEC for information related to risks and
uncertainties facing our business.
Okay. So, enjoy coming out here for this event. But let me kind of start with some of
the things that we are seeing here at NVIDIA. What is the last part of this year been
about in this important time?
The important time is related to really a change in how we see the data center
computing going forward, and the rise of Generative AI has really created a new
paradigm in front of us where we will see accelerated computing and AI computing
being the thrust of a lot of the computing going forward.
There's just an enormous installed base right now, about $1 trillion of compute that
has been about the same type for the last several decades. And this is the
opportunity that people see for both sustainability as we move forward at a more
eﬃcient way to do computing, but also to transact using AI, as AI will be with us in
almost everything that we do.
So it's a statement to say this is just the beginning of a journey. We have a huge
opportunity in front of us, and we look forward to more to come.
Yes, we gave our earnings just right before the Thanksgiving holiday to show both
strong growth, both sequentially and year-over-year growth for the company across
all of our market platforms. But a standout, of course, is our data center compute.
Our data center compute reached record levels, again, both for our training and
inferencing, also for our GPU sales and systems, but also our networking. We are
reaching more and more customers every day in terms of the work that we are
doing. The strength stem from our consumer Internet companies and a lot of our
enterprises.
Let's not forget our CSPs, also all growing in this last quarter, and we are continuing
to see more of our specialized and regional CSPs also grow.
So I just wanted to start it with just a beginning statement, and I'll turn it back over to
you, Aaron.
Questions And AnswersFINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 3 of 14A - Colette Kress
Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette Kress{BIO 18297352 <GO>}
(Question And Answer)
{BIO 6649630 <GO>}
That's perfect. So, I'm going to -- I've got -- I don't know, 50 questions here for you,
so we're going to try and get through as many as we can. But the inevitable question
I always get is, what does ﬁscal 1Q of '25 look like? And I think I know the answer
from you, but maybe I'll just start, kind of help us characterize the balance or the
imbalance, I should say, between the current supply and demand environment, what
NVIDIA is doing, and how do we think about the dynamic of lead times on some of
your higher-end SKUs and how does that start to progress or how should we think
about that progressing as we move forward?
{BIO 18297352 <GO>}
So an important look at this last year has been our ability to scale as a company for
the size of revenue. So some folks are really looking at it, that it must have been an
easy process. But it took a lot of work working with many of our supply channel, not
just in ordering supply, but keep in mind that it's also about ordering capacity. And
our long-term relationships with them was really helpful for us to be able to scale as
fast as we've had.
Unfortunately, we are still supply-constrained, though, and it's going to take us a little
while yet for us to catch up with that. We plan in terms of scaling supply both all of
this year in each quarter, but we also plan that as we go into '25. We're making
meaningful progress in terms of catching up with that supply.
Many folks look at both our ordering and seeing what we have in inventory, but keep
in mind, much of that is many diﬀerent durations, durations in terms of what we need
just today, what we are also procuring or solidifying for capacity in terms of the long
term.
So we're on track next year to make some meaningful progress right now in terms of
that supply and demand. But at the same time that we are serving demand, we are
also bringing new products to market. New products to market have therefore
surfaced the onset of now more demand coming in for our next set of products. And
I know we'll talk about that more.
{BIO 6649630 <GO>}
Yeah. That's perfect. I know, you just mentioned, right, like you had like if I add up
purchase commitments and inventory and prepaid capacity, it's like it grew 40%
sequentially this last quarter. But the point of that is that you would expect that to
continue to grow sequentially over the next handful of quarters.
{BIO 18297352 <GO>}
Correct.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 4 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette Kress{BIO 6649630 <GO>}
Kind of away from the supply side, the demand side, I guess how has your, if at all,
view on visibility changed, the demand visibility that you see, the demand shaping?
And the second piece of that question, I think last quarter when we talked last week,
you talked a little bit about product cycle, the cadence of product cycle as an
important variable to consider on product visibility. Maybe help us appreciate that a
little bit more.
{BIO 18297352 <GO>}
So when you think back over time of the many diﬀerent architecture generations that
we've gone through and what we are seeing today, our relationship with our
customers has grown stronger and stronger. And when that relationship comes to
helping them think through what they plan to build in terms of their data centers,
that's a longstanding discussion to help us both work with them in what is the exact
conﬁguration that they need, but it also helps us on demand visibility.
So our work with them continues each and every day. And if you think about how
long it would take to build a data center, from the beginning of day one of planning
to standing it up, that's likely a year if you are a very well-seasoned team that has
built up data centers.
So already we are seeing the work begin in terms of that next year, what do they
want to build? And the bringing together both our existing portfolio, our new
portfolio of products coming out, that again builds a relationship of more and more
demand as we go forward.
So, we'll continue that process. Our visibility is strong. And when we talk about our
visibility, each one of our customers knowing where we were with supply knew to
help us plan. They needed to provide us that deep understanding from essentially a
PO perspective. So, we'll continue that path right now with the new products and
maintain this process of understanding demand.
{BIO 6649630 <GO>}
Yeah. And just on a ﬁner point on that, if you look at the slide deck that you've put
out there on your Investor Relations website, you kind of outline that cadence of
product cycle, right? It's -- it looks like it's now more or less a year cadence, whereas
in the past, it might have -- that was a much longer cadence. So, that's part of this
visibility discussion that these customers are asking you for that kind of cadence of
product cycle, is it fair?
{BIO 18297352 <GO>}
That's correct. Additionally, the market has advanced so much, the complexity of the
type of AI and solutions that folks are working for, they would love to see something
new for each of their new plans that they have.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 5 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette KressAnd so for us to work on more diﬀerent products even in between architectures that
we can do as well as our architectures going forward to be on a faster cadence, that
is helpful to them. Both helpful from the planning, but also to support the new
projects that they're doing.
{BIO 6649630 <GO>}
That's perfect. So shifting gears a little bit, the competitive landscape -- I often get
the question of it's one of your competitors will launch a product next week. There
seems to be more and more narrative around like what the hyperscale cloud guys
are doing. I know AWS had Trainium 2 out this week or announcement. You've seen
what Microsoft announced recently. How do you characterize the competitive
landscape that you're seeing in data center?
{BIO 18297352 <GO>}
When we think about the work that we have done, we still step back and help folks
understand we didn't build a speciﬁc product or we didn't build a chip, we built a
full stack. We built many times a full data center. A data center for computing from
the minute information data enters the data center. You can work with NVIDIA, both
NVIDIA systems, NVIDIA's networking, NVIDIA's overall software stack, from just full
system software to really as close to the applications we can get. We help people
build models. We help people correct models. That's the work that we do.
So competitive is hard to look at because there isn't anything that is an apples-to-
apples in terms of what we're doing. They're all very, very diﬀerent. There can be
speciﬁc chips that may help certain speciﬁc workloads. But the reason that our
customers continue to turn to us is because of the TCO savings of purchasing a full
stack for them doesn't require them the signiﬁcant amount of resources that they
would have to add on top if they only had received just a chip. That work continues
for us to help support their TCO eﬀorts. So when we think about other types of
solutions coming to market, they're great.
But, again, our position is the more the merrier, that's ﬁne. But we do know TCO is
going to be the number-one goal of many of our customers today.
{BIO 6649630 <GO>}
And a lot of times I'll ﬁeld the question of it's CUDA, it's the 4.8 million developers,
it's the stack there. But it's so much deeper, right? It's -- I think we tend to get lost in
the CUDA stickiness, but is that a fair assessment? It's so much more than just the
CUDA layer.
{BIO 18297352 <GO>}
If you think about the onset of CUDA, CUDA being our development platform that's
on every single one of our GPUs and has been for close to 15 years, that is a building
of not only a very strong development platform but a community that has joined that
development platform. Everything that we do on our GPUs today is both backward-
compatible and forward-compatibility. Every customer knows that. They changed
generations of architectures to our new generation. Everything is still working.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 6 of 14Q - Aaron Rakers
A - Colette KressWe also have to think through where would that development community like to be.
They like to be where all the other developers are because so much work has been
built over time. Somebody would have to rebuild that. And so our position there has
just been a very full end-to-end solution that no one can overall argue with, and they
understand that we are here to continue to innovate going forward. They can count
on us that next year, yes, we are going to be thinking about new products for this
market as well.
{BIO 6649630 <GO>}
So I want to go down further down the layers of the stack strategy in a minute here,
networking, software, deﬁnitely want to touch on those. But before we go there, I
wanted to ask about the China restrictions. This recent round, I know last week you
had mentioned, look, we're going to have solutions that adhere to the restrictions of
selling to China within, quote-unquote, months.
You also mentioned though, that the China contribution would be down, quote-
unquote, signiﬁcantly this quarter. Help us think about that cadence. Like, is that --
did you kind of take out that full China business in your expectations this quarter?
And we start to see that come back as some of these solutions come into the market.
Is that how we think about it into the next quarter or two?
{BIO 18297352 <GO>}
The U.S. export controls this time were quite detailed, quite long, and took some
really thinking about how do we move forward to help our China customers. China is
still a very big market, not just for us but for much of the industry as a whole. And
when you look through the export controls, we have to carefully go through what is
just not an option that they would not approve. There's a new set of an area that says
up to notify and review with the government. And then there's an area that says carry
on, this is ﬁne for China.
Now what we want to do is make sure our both understanding and our relationship
with the U.S. Government remains as solid as it has. We've created a great
understanding of their needs, and we want to make sure we're following that. Keep
in mind, our China customers want to as well. If we will bring them a new product,
they do want to know that the U.S. government also agrees. And so we're working
through right now in terms of our design of what we think we could do. We will
certainly talk with the U.S. government and make sure that is also aligned with them.
Given that, that is an unknown deﬁned time, you are correct. We're not looking for
that to be a part of what we provided as an outlook for our Q4. And so the
sequential decline that we will see for China, keep in mind, we still will be selling for
our gaming business. We still bill for some of our other parts of our data center
business that we can sell in terms of that. But there would be a signiﬁcant change in
the quarter.
But going forward, we will. We'll support China with the approval and the
understanding of the of the U.S. government.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 7 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette Kress{BIO 6649630 <GO>}
Has the dialogue this round, relative to what the restrictions were, more bandwidth-
oriented at the ﬁrst kind of restriction? Has the dialogue with the U.S. government
changed? Has it deepened, as far as the engagement of solutions that will fall under
the thresholds of restrictions?
{BIO 18297352 <GO>}
Just given the complexity of the market, given the complexity of just semiconductors
as a whole, and the complexity of AI, yes, it was a much more thorough discussion
on both sides.
{BIO 6649630 <GO>}
Yes. And as far as the cadence of, you said months, right? As far as new solutions for
the China market.
{BIO 18297352 <GO>}
We're working as fast as we can.
{BIO 6649630 <GO>}
I got you, okay. Let's go down the stack a little bit more. A topic that I've written a lot
about, given my coverage universe, and this networking business, which I think
people are now really starting to see the signiﬁcance of it. To put some context to
that, when you bought Mellanox, the business was running $1.3 billion of revenue.
I think if my math's remotely right, you did $2.6 billion or even $2.7 billion of revenue
in networking. I know Jensen endorsed $10 billion plus of annualized revenue in this
last quarter. Help us appreciate that a little bit more. First of all, I want to know how
much is InﬁniBand, and then I'm going to get to Spectrum-X and how you see that
evolving as far as even deepening that networking strategy?
{BIO 18297352 <GO>}
Yeah, a great question regarding networking. At the time that we had completed the
acquisition, one of the things that we did know that it was a match of culture, a match
of culture in terms of how both teams worked on both innovation, thinking about
where the future would be, and had been really the basis of their data center was
high-performance computing, very similar to what we've done.
But we're so pleased in terms of how well the acquisition has both helped our
solutions for customers but our partnerships that we now have across so many of our
peers that are in Israel. And our work, you're correct, we've reached now an annual
run rate of nearly $10 billion in terms of our networking. That is looking where there's
a very sizable amount where we are together when we are selling GPU systems and
selling networks together.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 8 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette KressThey look for our high-end networking solutions. Why? Because they're the best-of-
the-breeds for accelerated computing and also for our AI solutions. If you are doing
AI, both training and the inferencing, the importance of InﬁniBand as the standard
for those large clusters is very, very key. So InﬁniBand has also grown even faster
than the total networking business that we have. And we have very large customers
that have been using it and installing it throughout, and that's an important part of
the process of building out their data center.
But we need to also understand that Ethernet for accelerated computing and AI is
also very key. And so our Spectrum-X will be coming out in the new calendar year.
That will be there again with the high speeds, moving from 400-gig to 800-gig, and
it will be very, very key, now based on Ethernet. Ethernet is important for enterprises
when they have the multi-tenancy types of data centers that they have, and we do
know that that is an important piece. So we're going to be able to really manage
both of these industries.
{BIO 6649630 <GO>}
So Colette, there's this debate about InﬁniBand, Ethernet, does Ethernet replace
InﬁniBand. Do you look at Spectrum-X as being accretive to the business or is it
either or? Or do they just play in diﬀerent pieces of this AI stack? I think a lot of your
white paper talks and delineates between AI factories versus AI cloud, and it seems
like that might be a delineation of Ethernet versus InﬁniBand. Maybe help us
understand where one plays and is it accretive to the model?
{BIO 18297352 <GO>}
It's absolutely accretive. This is not taken away. InﬁniBand, again, is a standard for
many that they will have. Now opening it up for those that are on Ethernet, it's an
addition in terms of that key place. It's true that we think about it from what will be
the AI factory. What will they standardize on versus what will they standardize, for
example, supercomputers that are built just for AI.
Thinking about the traﬃc that is coming into a data center, particularly for some of
these large inferencing platforms, that traﬃc and that traﬃc mitigation, both the
InﬁniBand and the new Spectrum-X really, really, really work to manage all of those
traﬃc challenges that may be there.
{BIO 6649630 <GO>}
Yes, that's perfect. And again, that's Q1, those come out. You've announced
partnerships with Dell and the server ecosystem. Okay, great. Kind of sticking on the
product portfolio, announcement this week, AWS is the ﬁrst deployer, I think, of the
GH200. So that's Grace Hopper, the combination of the ARM-based CPU and the
Hopper GPU. Talk a little bit about where that ﬁts in the strategy. What does Grace
Hopper look like as we start to think about that piece of the product portfolio going
forward?
{BIO 18297352 <GO>}FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 9 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette KressCorrect. So we came out with Grace Hopper 200, and we started shipping it within
Q3. Q3 was many of our supercomputer design wins that we have had. So it has
begun the shipping. But what we have now is Grace Hopper200 with Amazon and
with their AWS EC2 set.
Now, what is important about that is they will also take that to create a full
supercomputer dedicated to where you are now able to keep 32 GPUs together and
working, as well as a new revised NVLink within there. This is again yet that new
product introduction. We're excited to work with AWS. They will be standing up the
very ﬁrst GH200 as a CSP.
There will also be the opportunity for them working with us on DGX Cloud on
GH200 as well. So now working with customers on software and solutions using
GH200 just is a great opportunity both of using that Grace CPU, but also a complete
faster performance as a whole in terms of these.
{BIO 6649630 <GO>}
Is it going to be Grace Hopper, GH200, GH300, whatever the subsequent versions
might look like, or is there just a Grace? Is there a market for just an ARM-based CPU
from NVIDIA?
{BIO 18297352 <GO>}
There is an opportunity for just a Grace. There is an opportunity for just a Grace. New
product scenarios that we could see in the data center, you will likely see
opportunities for Grace as well.
{BIO 6649630 <GO>}
That's perfect. So I want to shift now to software, something we've also written a lot
about. And I think the reason for writing more and more about it is that I just hear
you becoming more vocal about it, right? You talked this last quarter, it's on pace to
hit a $1 billion in ARR. Can you walk us through the software monetization for
NVIDIA? Like the big drivers and certainly I'll have questions after that, but walk us
through the key drivers of the software side.
{BIO 18297352 <GO>}
We talk about our software more and more because it is an important reason, again,
why people choose our stack and why the success of the work that they're doing is
so successful. The years of our software building, there is software that comes with
every GPU, even though it is not foreseen as part of the invoice. It just says we'll
provide it in terms of free.
That is important and to the work that they're doing, but now there's a new
opportunity for us to look at software as a monetization as well, but there's reasons
for that. Our work is with enterprises. Our true end customer is the enterprises
around the world of all shapes and sizes for their work that they do.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 10 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette KressWhen they are building accelerated solutions or AI and they need help as they are
likely not staﬀed with a signiﬁcant amount of software engineers, that software stack
is essential. It's essential that things have been already pre-built, pre-designed that
they can work for and structure. They could also turn to us in terms of help,
assistance on ﬁxing models, optimizing models, and additional work for new
projects that they may be able to do.
Those enterprises are very focused in terms of seeing their AI computing in the same
frame that they see all of their computing that's in the data center. This is important
that our software now leverages and works with VMware, as most enterprises
leverage VMware to manage and operate all of their data center, all of their diﬀerent
workloads. So that is key for us to be a key part of this as we see the data centers in
the future becoming a very big portion of it being accelerated in AI.
Those enterprises are looking for a solution that says who's accountable for keeping
up that software? Who is providing the security platform with it? And how can I
create a trusting relationship with it? That is why it monetizes. That's why this is
something that we can actually sell in that piece. NVIDIA AIE is our software platform,
essentially the AI operating system for the enterprises that will be a very big part of
our software probably going forward. We have other diﬀerent components as well.
Omniverse is a key component and let's not forgot -- forget our AV software for
automotive that will be with us. These things will scale not only with just our types of
customers but just because of our infrastructure. As people install more and more
infrastructure, that operating system will be important will be important for them to
use.
{BIO 6649630 <GO>}
So if I think about $1 billion ARR this year, is it fair to say that the overwhelming
majority of that, unless you want to give me a number, which I don't think you will, is
the overwhelming majority of that AIE, AI enterprise software today?
{BIO 18297352 <GO>}
There's a lot of diﬀerent pieces in there, but most of it is associated with what's
going to the data center and a lot of diﬀerent data center components.
{BIO 6649630 <GO>}
And that's interesting, because do you think that that consumption model is through
your cloud partners? Again, now that I look at it, you've got Oracle, Microsoft, Azure,
Google, and just this week, DGX at AWS as well. Is it consumed through your cloud
partners or is it consumed on traditional enterprise on-premise infrastructure?
{BIO 18297352 <GO>}
Yeah. The great thing is it's consumed in almost every form of the channel that you
can think through. If you have in terms of, I'm going to self-design it with an ODM or
with a Dell with an HP, or I'm going to have cloud credits and work with my cloudFINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 11 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakerscustomers and download the software in terms of their, all of these are opportunities
for them to procure our software. Making it easy for that integration, you can pretty
much get it in a lot of diﬀerent places.
{BIO 6649630 <GO>}
So through the cloud guys, price per GPU per hour.
{BIO 18297352 <GO>}
That's correct.
{BIO 6649630 <GO>}
Fast model.
{BIO 18297352 <GO>}
It is. You should look at it. Somewhere in the range of about a $4,500 to $5,000 per
year per GPU type of load. Somewhere in that range is what we're looking at.
{BIO 6649630 <GO>}
Okay. And I've asked you this many times after conference calls and stuﬀ. One of the
metrics you guys talk about is these multi-year cloud service agreement numbers.
Some of that's internal usage. A lot of that might be internal usage, right? I'm always
looking for that leading indicator on the software side. Some of that is actually your
potential payment to your cloud partners for the infrastructure for the software. It's
actually -- is that a fair assessment.
{BIO 18297352 <GO>}
So we have cloud service agreements, just like every other enterprise has out there.
Our cloud service agreements serve many diﬀerent uses. The ability for them to
stand up in the cloud so we can understand what enterprises are facing, and then we
are using that to test our software, test our future solutions, and work with them on
new use cases for products. We do this all the time.
So we have -- most of that right now has been centered around our internal use. But
now we are building for DGX Cloud to where we have established space within the
CSPs. So for any customer coming in from an enterprise and says we'd like your DGX
Cloud, we can move them across multiple diﬀerent CSPs. They are not having to be
in any one, we're just being in almost all of them. And that will help them as quickly
come to market as they can on their product solutions.
{BIO 6649630 <GO>}
So two other real quick, on the software side. So Omniverse, I want to say, if my
memory's right, kind of initially introduced back in the latter part of '21-ish timeframe,
maybe I'm a year old, I don't know. I don't remember, but is that the progression of
that software piece? It just takes a little bit longer, it's more signiﬁcant changes.FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 12 of 14A - Colette Kress
Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakers
A - Colette Kress{BIO 18297352 <GO>}
It's a great progress already in terms of what we're seeing in Omniverse. Working
with very large manufacturing and factory types of builds. And the importance of the
work that they need to do to redesign and/or initially design any one of those
factories for the most eﬃciency. They are using Omniverse very clearly. So many of
the large car companies and car manufacturers are really looking at Omniverse to
help them in there.
But you can see this to almost any type of factory that is being built, industrial types
of factories or warehousing. And how do I redesign that? Because you have the
ability to create a complete digital twin of your existing and/or future without going
through that full prototype of a building and making large errors through it by using
an Omniverse environment.
What happens is, each and every day, more types of uses come to Omniverse as we
add many diﬀerent more prescriptions that they need to do their work. That's always
going to be added. And so it will be a continuous evolution. But that's 3D type of
view versus a 2D which is used so much in terms of design and build will be
essential. So, yes, we're pleased with the progress and we'll continue to see it in the
future.
{BIO 6649630 <GO>}
And then the ﬁnal thing on software, automotive, am I still thinking like Mercedes
ﬂagship, Jaguar Land Rover ﬂagship 2025, 2026 timeframe?
{BIO 18297352 <GO>}
Absolutely. We are busy working, but yes, that's when we expect the pilots to start as
also the full ﬂeet for both of those companies.
{BIO 6649630 <GO>}
So, I've got 3.5 minutes left. I'm going to maybe rapid ﬁre through a couple quick
questions. So, mix has been a huge driver of the business. Where do we think gross
margin should go? I mean, it's remarkable, right? You're 75% gross margin. How do
we think about the trajectory of gross margin? It seems like data center mix will
continue to go higher. Software is going to layer on top of that. How should we think
about that?
{BIO 18297352 <GO>}
Yeah. So, when you think about our gross margin, although it is an important metric
for many of us on the P&L, keep in mind it doesn't capture everything when we talk
about both our ASP or we think about the actual manufacturing costs. It really just is
the manufacturing costs that are included in that because the work that we did in
terms of the designing the software that is in many of this and/or just the full
engineering work on many other solutions that keep giving even after we haveFINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 13 of 14Q - Aaron Rakers
A - Colette Kress
Q - Aaron Rakersshipped the product, doesn't easily get represented. Most of that is still in the OPEC.
So it's a metric and it's an important metric.
And so the 75 given our size of our data center business, you are now seeing the
company margins and the data center margins to kind of be about the same
because what you are seeing as a company total is mostly just that data center. We
believe this is about a level where it will stay with the continuation, at this point,
probably being software and software adding to that. But we think you are pretty
much now seeing the data center one.
{BIO 6649630 <GO>}
That's perfect. And then the other quick question I want to ask is that you actually,
this last quarter, with $18 plus billion of cash in a balance sheet, I think everybody can
look at a model and say that you guys are going to generate a lot of cash. How do
you think about strategic M&A, like this platform strategy, Mellanox home run,
obviously armed in play out, but how do you think about the balance of strategic,
maybe platform expanding M&A activity for the company?
{BIO 18297352 <GO>}
Yeah, I'd say ﬁrst stepping back, cash allocation is a very top priority to make sure we
can think of all the right avenues that we want to apply that cash. Always going to be
ﬁrst is an investment back into the business, whether that be capital back into it,
whether it be OpEx in it. Investing in the business innovation just right ﬁrst write-oﬀ is
going to be our number one use of cash.
Secondly, we do want to make sure that our investors get their portion, and we want
to make sure that we can not have any dilution associated with our equity that we
provide to employees. Our equity to employees is very important. That is a very
important part of their compensation. But we do want to keep that dilution about as
ﬂat as possible.
After that, we look in terms of investments every single day, investments that we can
learn from many companies in terms of the work that they are doing, but also
working with other companies, is this an opportunity for M&A. It's hard to have found
the perfect Mellanox of the past and think that would be easy to ﬁnd again. It's a new
environment in terms of right now of the M&A environment, but it doesn't mean that
we still look. We look in terms of smaller companies, teams that are bringing a
unique ad to our company, and that would be something that we'll look at all the
time.
{BIO 6649630 <GO>}
So we've got literally 12 seconds left, 10. I'm going to ask you just the one pointed
question, which is, you talk to hundreds of investors after earnings, right? You --
you're in, -- earnings don't end, and then you go and do something else. It's a
continual ﬂywheel of discussion. What are you surprised that people aren't asking
you about more? Is there any topic where you're like, man, I'm surprised I'm not
getting this question? What would that be?FINAL TRANSCRIPT 2023-11-29
NVIDIA Corp (NVDA US Equity)
Page 14 of 14A - Colette Kress
Q - Aaron Rakers
A - Colette Kress{BIO 18297352 <GO>}
The surprise of the question that I am not getting. Well, I would look at it as our goal
in terms of earnings and the reasons why we do, these talks like this is to make sure
the clarity of our products, the clarity in terms of accelerating computing and why
there has been this growth has been an important part of us.
And so I do believe the questions mainly surround a little bit more detail that I won't
add, but they have gotten a very clear understanding that, with Generative AI, there
has been such a signiﬁcant change of the focus of enterprises around the world,
focusing on building out their AI solutions for their enterprises.
Each enterprise looks and says the future is about using enterprise AI, otherwise they
will not be able to compete in the market. That's a pretty big market to go after and
work through. This is important to think about our focus on sovereign AI has come
forth. And folks have asked, what do we mean by that? That has been probably an
important key understanding. We're speaking here, we're in the U.S.
We see ChatGPT. ChatGPT is U.S. culture, U.S. data, U.S. ways to think. Each and
every nation and/or region wants the same thing. They also know that they would
therefore have proprietary data and information as well. So not only do we speak
with so many diﬀerent enterprises in their work right now to add AI, we are working
with many regions also to build out what they need.
{BIO 6649630 <GO>}
Collette, we're over time. I appreciate you joining us this morning. Thank you so
much.
{BIO 18297352 <GO>}
Thank you.
This transcript may not be 100 percent accurate and may contain misspellings and 
other inaccuracies. This transcript is provided "as is", without express or implied 
warranties of any kind. Bloomberg retains all rights to this transcript and provides it 
solely for your personal, non-commercial use. Bloomberg, its suppliers and third-
party agents shall have no liability for errors in this transcript or for lost proﬁts, losses, 
or direct, indirect, incidental, consequential, special or punitive damages in 
connection with the furnishing, performance or use of such transcript. Neither the 
information nor any opinion expressed in this transcript constitutes a solicitation of 
the purchase or sale of securities or commodities. Any opinion expressed in the 
transcript does not necessarily reﬂect the views of Bloomberg LP. © COPYRIGHT 
2024, BLOOMBERG LP. All rights reserved. Any reproduction, redistribution or 
retransmission is expressly prohibited.